{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQFHuLvvXEDCGQCap8NVO/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SangBeom-Hahn/BOAZ/blob/main/CNN_%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8_2%EC%B0%A8_grayscale_%EC%84%B1%EA%B3%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 32 by 32가 해상도가 낮아서 못 알아들으니 해상도가 큰 모델을 만들어보자\n",
        "\n",
        "1) 제목에 맞게resnet으로 예측\n",
        "\n",
        "2) 내 모델을 224 by 224 by 3에 맞게 만들어서 mnist를 224 by 224로 만들어서 학습시키고 예측해보자(해상도를 높였으니 잘 알아보나 실험)\n",
        "\n",
        "3) 그레이 스케일을 잘 해보자(유튜브 참고)"
      ],
      "metadata": {
        "id": "tV_FFZ17QEsG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) resnet으로 예측"
      ],
      "metadata": {
        "id": "ghASADRJQ6fu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fw43wB4HHXT6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# include_top을 하면 vgg 분류기까지 가져온다는 얘기\n",
        "model = VGG16(weights='imagenet', include_top=True) \n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
        "\n",
        "# resize into VGG16 trained images' format\n",
        "im = cv2.resize(cv2.imread('/content/123.jpg'), (224, 224))\n",
        "im = np.expand_dims(im, axis=0) # 1, 224, 224, 3이 됨\n",
        "# im = im.reshape(1,im.shape[0],im.shape[1], im.shape[2])\n",
        "im.astype(np.float32)\n",
        "\n",
        "print(type(im))\n",
        "\n",
        "# predict\n",
        "out = model.predict(im)\n",
        "index = np.argmax(out)\n",
        "print(index)\n",
        "\n",
        "#plt.plot(out.ravel())\n",
        "#plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3oOyADCRBUT",
        "outputId": "d5fc2e0d-4283-4fdd-bbad-d114d9682508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f47bae27290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 넘파이화 실험\n",
        "\n",
        "-> 무조건 넘파이화 해야한다."
      ],
      "metadata": {
        "id": "1mB3krIhR2NJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# include_top을 하면 vgg 분류기까지 가져온다는 얘기\n",
        "model = VGG16(weights='imagenet', include_top=True) \n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
        "\n",
        "# resize into VGG16 trained images' format\n",
        "im = cv2.resize(cv2.imread('/content/123.jpg'), (224, 224))\n",
        "im = np.array(im)\n",
        "im = np.expand_dims(im, axis=0) # 1, 224, 224, 3이 됨\n",
        "im.astype(np.float32)\n",
        "\n",
        "print(type(im))\n",
        "\n",
        "# predict\n",
        "out = model.predict(im)\n",
        "index = np.argmax(out)\n",
        "print(index)\n",
        "\n",
        "#plt.plot(out.ravel())\n",
        "#plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYEY14IJRYZt",
        "outputId": "3739ca91-5582-4c1c-96e3-8c36e9c8b717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7iiQ-Gb2SuoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nHmTaO7XTW8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wPiaCOEyTW52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) 내 모델을 224 by 224 by 3에 맞게 만들어서 mnist를 224 by 224로 만들어서 학습시키고 예측해보자\n",
        "\n",
        "궁금증 1 : 어떨땐 모델 input이 32, 32이고 어떨떈 32, 32, 3이지? -> 채널이 1이 아니면 무조건 3을 붙어야하나?\n",
        "\n",
        "해결 : cnn이면 모델 input shape를 32 * 32 * 3으로하고 학습이미지도 60000 * 32 * 32 * 3으로 reshape해야하고 실험으로 넣을 이미지도 1 * 32 * 32 * 3으로 넣어야함\n",
        "\n",
        "-> dnn이면 전부 다 채널 필요 없음/\n"
      ],
      "metadata": {
        "id": "_Xj7nCtFTXM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, optimizers\n",
        "import cv2\n",
        "\n",
        "#define the convnet \n",
        "class LeNet:\n",
        "\t@staticmethod\n",
        "\tdef build(input_shape, classes):\n",
        "\t\tmodel = models.Sequential()\n",
        "\t\t# CONV => RELU => POOL\n",
        "\t\tmodel.add(layers.Convolution2D(20, (5, 5), activation='relu',\n",
        "\t\t\tinput_shape=INPUT_SHAPE))\n",
        "\t\tmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\t\t# CONV => RELU => POOL\n",
        "\t\tmodel.add(layers.Convolution2D(50, (5, 5), activation='relu'))\n",
        "\t\tmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\t\t# Flatten => RELU layers\n",
        "\t\tmodel.add(layers.Flatten())\n",
        "\t\tmodel.add(layers.Dense(500, activation='relu'))\n",
        "\t\t# a softmax classifier\n",
        "\t\tmodel.add(layers.Dense(classes, activation=\"softmax\"))\n",
        "\t\treturn model\n",
        "\n",
        "\n",
        "\n",
        "# network and training\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "OPTIMIZER = tf.keras.optimizers.Adam()\n",
        "VALIDATION_SPLIT=0.90\n",
        "\n",
        "IMG_ROWS, IMG_COLS = 224, 224 # input image dimensions\n",
        "INPUT_SHAPE = (IMG_ROWS, IMG_COLS)\n",
        "NB_CLASSES = 10  # number of outputs = number of digits\n",
        "\n",
        "# data: shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
        "\n",
        "# reshape\n",
        "X_train = X_train.reshape((60000, 28, 28, 1))\n",
        "X_test = X_test.reshape((10000, 28, 28, 1))\n",
        "\n",
        "\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8t58cu7TYBq",
        "outputId": "4f3a3f60-c026-4a67-a87f-e4382a110a9e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cv로 하면 한장한장씩 resize 해야하는데? tf로하면 한 번에 됨 근데 ram 터짐,,,ㅋㅋㅋ\n",
        "\n",
        "-> resize랑 reshape만 잘쓰면 되네~ 근데 mnist 784개가 224 * 224만큼 안 나와서 안된다 + 3)으로 원하는 거 성공했으니 패스!"
      ],
      "metadata": {
        "id": "cYmCH8NWVnnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# im = cv2.resize(cv2.imread('/content/123.jpg'), (224, 224))\n",
        "# X_train = cv2.resize(X_train, (224, 224))\n",
        "# X_test = cv2.resize(X_test, (224, 224))"
      ],
      "metadata": {
        "id": "2eCDkaSYU5hN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = tf.image.resize(X_train, [224, 224])\n",
        "# X_test = tf.image.resize(X_test, [224, 224])\n",
        "# print(X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "BjFlH2KzVTIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = img.reshape((-1, 28, 28, 1))"
      ],
      "metadata": {
        "id": "VjovYGwUrEQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(X_train.shape[0]):\n",
        "  X_train[i] = X_train[i].reshape((-1, 224, 224, 1))\n",
        "\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "u83hAf51eUXh",
        "outputId": "96d00878-7c47-4b87-bb53-7c56902632ab"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-c8207e1a7b83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 784 into shape (224,224,1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "# cast\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = tf.keras.utils.to_categorical(y_train, NB_CLASSES)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, NB_CLASSES)\n",
        "\n",
        "# initialize the optimizer and model\n",
        "model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "# use TensorBoard, princess Aurora!\n",
        "callbacks = [\n",
        "  # Write TensorBoard logs to `./logs` directory\n",
        "  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
        "]\n",
        "\n",
        "# fit \n",
        "history = model.fit(X_train, y_train, \n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS, \n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT,\n",
        "\t\tcallbacks=callbacks)\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score:\", score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "s3qeGw_CTs0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x9H-rvP7hFRn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z0LnH3kChFP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YbJGNcSkhFMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4uwAa8LUhFKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "riAyKH6rhFID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sISPXELKhFGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 성공~~~축하해\n",
        "\n",
        "# 3) gray scale \n",
        "\n",
        "https://copycoding.tistory.com/225\n",
        "\n",
        "○ CV\n",
        "- 데이터 모양 처리\n",
        "1. img = cv2.imread(\"/content/제목 없음.png\", cv2.2/IMREAD_GRAYSCALE)\n",
        "2. img = cv2.resize(255-img, (28, 28)) # 이것만 해도 원래 안됐던 reshape은 됨\n",
        "3. img = img.flatten() / 255.0\n",
        "4. img = img.reshape((-1, 28, 28, 1))\n",
        "\n",
        "※부수적인 것 5. 실수화 : im.astype(np.float32) ↑ 이 위에서 넘파이화는 이미 되어있다/"
      ],
      "metadata": {
        "id": "C9vrK2QyhFkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "9W7E-OWThItw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((60000, 28, 28, 1))\n",
        "X_test = X_test.reshape((10000, 28, 28, 1))"
      ],
      "metadata": {
        "id": "jGBGF5lCkQPr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = X_train / 255.0, X_test / 255.0"
      ],
      "metadata": {
        "id": "zfbcVGWghhPz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, optimizers\n",
        "\n",
        "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
        "IMG_CHANNELS = 1\n",
        "IMG_ROWS = 28\n",
        "IMG_COLS = 28\n",
        "\n",
        "#constant\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 20\n",
        "CLASSES = 10\n",
        "VERBOSE = 1\n",
        "VALIDATION_SPLIT = 0.2\n",
        "OPTIM = tf.keras.optimizers.RMSprop()\n",
        "\n",
        "#define the convnet \n",
        "def build(input_shape, classes):\n",
        "\tmodel = models.Sequential() \n",
        "\tmodel.add(layers.Convolution2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=input_shape))\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\tmodel.add(layers.Dropout(0.25)) \n",
        "\n",
        "\tmodel.add(layers.Flatten())\n",
        "\tmodel.add(layers.Dense(512, activation='relu'))\n",
        "\tmodel.add(layers.Dropout(0.5))\n",
        "\tmodel.add(layers.Dense(classes, activation='softmax'))\n",
        "\treturn model\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, CLASSES)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, CLASSES)\n",
        "\n",
        "model=build((IMG_ROWS, IMG_COLS, IMG_CHANNELS), CLASSES)\n",
        "# model=build((IMG_ROWS, IMG_COLS), CLASSES)\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
        "\tmetrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDH_tkJjh0pA",
        "outputId": "d6c7880c-2683-4623-8cb4-14dfffd10547"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 13, 13, 32)        0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 5408)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               2769408   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,774,858\n",
            "Trainable params: 2,774,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQLLbmXjiPez",
        "outputId": "c83263d2-be5e-4009-f3be-9208dfb5bb9f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 101s 53ms/step - loss: 0.1755 - accuracy: 0.9467\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0830 - accuracy: 0.9752\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0719 - accuracy: 0.9791\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 99s 53ms/step - loss: 0.0705 - accuracy: 0.9801\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 103s 55ms/step - loss: 0.0680 - accuracy: 0.9809\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f173c2964d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score:\", score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbGLAVImiYEU",
        "outputId": "5dc58238-f071-4947-90fb-087d6f68bd3e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0538 - accuracy: 0.9830\n",
            "\n",
            "Test score: 0.0538104847073555\n",
            "Test accuracy: 0.9829999804496765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = Image.open(\"/content/제목 없음.png\")\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "FqH1YsX-m1Tm",
        "outputId": "11db9163-0581-4a04-a44b-4f722a8b12ba"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "img = cv2.imread(\"/content/제목 없음.png\", cv2.IMREAD_GRAYSCALE)"
      ],
      "metadata": {
        "id": "3wOzPm61nhOL"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6QKTaIkoZhh",
        "outputId": "df88742c-ff68-4752-ed25-5f01e635fc6b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(296, 323)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.resize(255-img, (28, 28)) # 이것만 해도 원래 안됐던 reshape은 됨"
      ],
      "metadata": {
        "id": "oXYKCu7aoiY8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = img.flatten() / 255.0\n",
        "img = img.reshape((-1, 28, 28, 1))"
      ],
      "metadata": {
        "id": "Xd8FreQApAm_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVnFLiJUpXKn",
        "outputId": "73226ed8-0a79-4c83-a3c5-2a468e6c3ef5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 여전히 이건 안됨\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "xWrxm6IzowFU",
        "outputId": "6043a263-8d53-45e8-f166-c84296cb0729"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-878eb3b29097>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (1, 28, 28, 1) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = model.predict(img, verbose=0) \n",
        "predicted = y_prob.argmax(axis=-1)"
      ],
      "metadata": {
        "id": "qUrMoz8Mn46d"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xweXb1aepeMX",
        "outputId": "04e83559-f60b-4588-a489-b31eb7fe6bb7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cIH-uU9mpoEp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
