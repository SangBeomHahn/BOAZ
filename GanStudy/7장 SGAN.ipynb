{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ljbg3v72_m_B"},"outputs":[],"source":["%matplotlib inline\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from tensorflow.keras import backend as K\n","\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.layers import (Activation, BatchNormalization, Concatenate, Dense,\n","                                     Dropout, Flatten, Input, Lambda, Reshape)\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical"]},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, num_labeled):\n","\n","        # 훈련에 사용할 레이블된 샘플 개수\n","        self.num_labeled = num_labeled\n","\n","        # MNIST 데이터셋 적재\n","        (self.x_train, self.y_train), (self.x_test,\n","                                       self.y_test) = mnist.load_data()\n","\n","        def preprocess_imgs(x):\n","            # [0, 255] 사이 흑백 픽셀 값을 [–1, 1] 사이로 변환\n","            x = (x.astype(np.float32) - 127.5) / 127.5\n","            # 너비 × 높이 × 채널로 이미지 차원을 확장\n","            x = np.expand_dims(x, axis=3)\n","            return x\n","\n","        def preprocess_labels(y):\n","            return y.reshape(-1, 1)\n","\n","        # 훈련 데이터\n","        self.x_train = preprocess_imgs(self.x_train)\n","        self.y_train = preprocess_labels(self.y_train)\n","\n","        # 테스트 데이터\n","        self.x_test = preprocess_imgs(self.x_test)\n","        self.y_test = preprocess_labels(self.y_test)\n","\n","\n","\n","\n","    def batch_labeled(self, batch_size):\n","        # 레이블된 이미지와 레이블의 랜덤 배치 만들기\n","        idx = np.random.randint(0, self.num_labeled, batch_size) # 0, 100 사이 숫자 batch_size 개수 만큼 랜덤 생성 \n","        # 레이블 데이터는 0~100 사이에서 뽑는다.\n","\n","\n","        imgs = self.x_train[idx]\n","        labels = self.y_train[idx]\n","        return imgs, labels\n","\n","\n","\n","    def batch_unlabeled(self, batch_size):\n","        # 레이블이 없는 이미지의 랜덤 배치 만들기\n","\n","        # 언레이블 데이터는 100~60000 사이에서 뽑는다.\n","        idx = np.random.randint(self.num_labeled, self.x_train.shape[0],\n","                                batch_size)\n","        imgs = self.x_train[idx]\n","        return imgs\n","\n","\n","\n","\n","    def training_set(self): # 0~99 데이터 X, Y로 쓰겟다.\n","        x_train = self.x_train[range(self.num_labeled)]\n","        y_train = self.y_train[range(self.num_labeled)]\n","        return x_train, y_train\n","\n","    def test_set(self):\n","        return self.x_test, self.y_test"],"metadata":{"id":"ryB7_jnCFPne"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 사용할 레이블된 샘플 개수 (나머지는 레이블없이 사용합니다)\n","num_labeled = 100\n","\n","dataset = Dataset(num_labeled)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZvitY2IIGBcm","executionInfo":{"status":"ok","timestamp":1663838069883,"user_tz":-540,"elapsed":505,"user":{"displayName":"한상범","userId":"04261387817205784779"}},"outputId":"04bc3f01-89ec-4040-8025-e233e808cc11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["img_rows = 28\n","img_cols = 28\n","channels = 1\n","\n","# 입력 이미지 차원\n","img_shape = (img_rows, img_cols, channels)\n","\n","# 생성자의 입력으로 사용할 잡음 벡터의 크기\n","z_dim = 100\n","\n","# 데이터셋에 있는 클래스 개수\n","num_classes = 10"],"metadata":{"id":"mfxx292RGN9H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_generator(z_dim):\n","\n","    model = Sequential()\n","\n","    # 완전 연결 층을 사용해 입력을 7 × 7 × 256 크기 텐서로 바꿉니다.\n","    model.add(Dense(256 * 7 * 7, input_dim=z_dim))\n","    model.add(Reshape((7, 7, 256)))\n","\n","    # 7 × 7 × 256에서 14 × 14 × 128 텐서로 바꾸는 전치 합성곱 층\n","    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n","\n","    # 배치 정규화\n","    model.add(BatchNormalization())\n","\n","    # LeakyReLU 활성화 함수\n","    model.add(LeakyReLU(alpha=0.01))\n","\n","    # 14 × 14 × 128에서 14 × 14 × 64 텐서로 바꾸는 전치 합성곱 층\n","    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n","\n","    # 배치 정규화\n","    model.add(BatchNormalization())\n","\n","    # LeakyReLU 활성화 함수\n","    model.add(LeakyReLU(alpha=0.01))\n","\n","    # 14 × 14 × 64에서 28 × 28 × 1 텐서로 바꾸는 전치 합성곱 층\n","    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))\n","\n","    # tanh 활성화 함수\n","    model.add(Activation('tanh'))\n","\n","    return model"],"metadata":{"id":"pNWZ6Tg8NEUN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_discriminator_net(img_shape):\n","\n","    model = Sequential()\n","\n","    # 28 × 28 × 1에서 14 × 14 × 32 텐서로 바꾸는 합성곱 층\n","    model.add(\n","        Conv2D(32,\n","               kernel_size=3,\n","               strides=2,\n","               input_shape=img_shape,\n","               padding='same'))\n","\n","    # LeakyReLU 활성화 함수\n","    model.add(LeakyReLU(alpha=0.01))\n","\n","    # 14 × 14 × 32에서 7 × 7 × 64 텐서로 바꾸는 합성곱 층\n","    model.add(\n","        Conv2D(64,\n","               kernel_size=3,\n","               strides=2,\n","               padding='same'))\n","    \n","    # LeakyReLU 활성화 함수\n","    model.add(LeakyReLU(alpha=0.01))\n","\n","    # 7 × 7 × 64에서 3 × 3 × 128 텐서로 바꾸는 합성곱 층\n","    model.add(\n","        Conv2D(128,\n","               kernel_size=3,\n","               strides=2,\n","               padding='same'))\n","    \n","    # LeakyReLU 활성화 함수\n","    model.add(LeakyReLU(alpha=0.01))\n","\n","    # 드롭아웃\n","    model.add(Dropout(0.5))\n","\n","    # 텐서 펼치기\n","    model.add(Flatten())\n","\n","    # num_classes 개의 뉴런을 가진 완전 연결 층\n","    model.add(Dense(num_classes))\n","\n","    return model"],"metadata":{"id":"gLKf_slBOW1t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_discriminator_supervised(discriminator_net):\n","\n","    model = Sequential()\n","\n","    model.add(discriminator_net) # 이게 Dense로 끝나서 마지막 activation만 더해주면 된다.\n","\n","    # 진짜 클래스에 대한 예측 확률을 출력하는 소프트맥스 활성화 함수\n","    model.add(Activation('softmax'))\n","\n","    return model"],"metadata":{"id":"007u5YXTO4OE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_discriminator_unsupervised(discriminator_net):\n","\n","    model = Sequential()\n","\n","    model.add(discriminator_net)\n","\n","    def predict(x):\n","        # 진짜 클래스에 대한 확률 분포를 진짜 대 가짜의 이진 확률로 변환합니다.\n","        prediction = 1.0 - (1.0 /\n","                            (K.sum(K.exp(x), axis=-1, keepdims=True) + 1.0))\n","        return prediction\n","\n","    # 앞서 정의한 진짜 대 가짜 확률을 출력하는 뉴런\n","    model.add(Lambda(predict))\n","\n","    return model"],"metadata":{"id":"aLSqCWiTPfB0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### GAN 모델 구성"],"metadata":{"id":"9W0S9GHcTBaP"}},{"cell_type":"markdown","source":["- 3장 GAN 구현 코드임 비교해보라\n","\n","\n","https://colab.research.google.com/drive/1BtG2tsyHmPdU0TqMg53PaZ4wB47We7np#scrollTo=MMDjz-ydmloS"],"metadata":{"id":"9LAVUuY9THiH"}},{"cell_type":"code","source":["def build_gan(generator, discriminator):\n","\n","    model = Sequential()\n","\n","    # 생성자와 판별자 모델을 연결하기\n","    model.add(generator)\n","    model.add(discriminator)\n","\n","    return model"],"metadata":{"id":"Wcm7haBgPnyG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 판별자 기반 모델: 이 층들은 지도 학습 훈련과 비지도 학습 훈련에 공유됩니다.\n","discriminator_net = build_discriminator_net(img_shape) # 판별자 모델이 지도와 비지도에 공유됨\n","\n","# 지도 학습 훈련을 위해 판별자를 만들고 컴파일합니다.\n","discriminator_supervised = build_discriminator_supervised(discriminator_net)\n","discriminator_supervised.compile(loss='categorical_crossentropy', # 카테고리컬(지도학습)\n","                                 metrics=['accuracy'],\n","                                 optimizer=Adam(learning_rate=0.0003))\n","\n","\n","\n","# 비지도 학습 훈련을 위해 판별자를 만들고 컴파일합니다.\n","discriminator_unsupervised = build_discriminator_unsupervised(discriminator_net)\n","discriminator_unsupervised.compile(loss='binary_crossentropy', # 비지도 바이너리\n","                                   optimizer=Adam())"],"metadata":{"id":"X5qa3aLsTDYW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 생성자를 만듭니다.\n","generator = build_generator(z_dim)\n","\n","# 생성자 훈련을 위해 판별자의 모델 파라미터를 동결합니다.\n","discriminator_unsupervised.trainable = False\n","\n","# 생성자를 훈련하기 위해 고정된 판별자로 GAN 모델을 만들고 컴파일합니다.\n","# 노트: 비지도 학습용 판별자를 사용하세요.\n","\n","\n","\n","gan = build_gan(generator, discriminator_unsupervised) # GAN 모델은 일단 비지도 모델만 가져다 만든다. -> build GAN의 파라미터도 2개만 받음\n","gan.compile(loss='binary_crossentropy', optimizer=Adam())"],"metadata":{"id":"OIGNEwawToUQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["supervised_losses = [] #이건 그저 손실을 그래프로 그리긴 위한 배열\n","iteration_checkpoints = []\n","\n","\n","def train(iterations, batch_size, sample_interval):\n","\n","    # 진짜 이미지의 레이블: 모두 1\n","    real = np.ones((batch_size, 1))\n","\n","    # 가짜 이미지의 레이블: 모두 0\n","    fake = np.zeros((batch_size, 1))\n","\n","    for iteration in range(iterations):\n","\n","        # -------------------------\n","        #  판별자 훈련\n","        # -------------------------\n","\n","# 새로운 부분\n","        # 레이블된 샘플을 가져옵니다.\n","        imgs, labels = dataset.batch_labeled(batch_size) # 레이블된 이미지 100개 가져옴 -> x, y가 같이 있는 라벨 데이터\n","\n","        # 레이블을 원-핫 인코딩합니다.\n","        labels = to_categorical(labels, num_classes=num_classes) # 가져온 레이블은 소맥할 거니 원핫 인코딩\n","\n","\n","\n","\n","\n","#원래 이진 분류 데이터 가져오기===================================================================================================================================================\n","\n","        # 레이블이 없는 샘플을 가져옵니다.\n","        imgs_unlabeled = dataset.batch_unlabeled(batch_size) # 레이블 없는 59900개 가져옴 -> x만 있는 언라벨 데이터\n","\n","        # 가짜 이미지의 배치를 생성합니다.\n","        z = np.random.normal(0, 1, (batch_size, z_dim)) # 0~1수 배치사이즈행 z_dim열을 만듬\n","        gen_imgs = generator.predict(z) #-> 그니깐 이게 원래 판별기에 진짜와 가짜로 이진 분류 하는 부분\n","\n","#새로운 다중 분류 손실===================================================================================================================================================\n","\n","\n","        # 레이블된 진짜 샘플에서 훈련합니다.\n","        d_loss_supervised, accuracy = discriminator_supervised.train_on_batch(imgs, labels)\n","\n","\n","#원래 이진 분류 손실===================================================================================================================================================\n","\n","\n","        # 레이블이 없는 진짜 샘플에서 훈련합니다.\n","        d_loss_real = discriminator_unsupervised.train_on_batch(imgs_unlabeled, real)\n","\n","        # 가짜 샘플에서 훈련합니다.\n","        d_loss_fake = discriminator_unsupervised.train_on_batch(gen_imgs, fake)\n","\n","        d_loss_unsupervised = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","\n","#===================================================================================================================================================\n","\n","\n","\n","        # ---------------------\n","        #  생성자 훈련\n","        # ---------------------\n","\n","        # 가짜 이미지의 배치를 생성합니다.\n","        z = np.random.normal(0, 1, (batch_size, z_dim)) \n","        gen_imgs = generator.predict(z)\n","\n","        # 생성자를 훈련합니다.\n","        g_loss = gan.train_on_batch(z, np.ones((batch_size, 1))) # 생성자는 가짜가 1이라고 말함 (32, 1)하면 32행에 대한 라벨이 다 1로 생김\n","\n","        if (iteration + 1) % sample_interval == 0:\n","\n","            # 훈련이 끝난 후 그래프를 그리기 위해 판별자의 지도 학습 분류 손실을 기록합니다.\n","            supervised_losses.append(d_loss_supervised)\n","            iteration_checkpoints.append(iteration + 1)\n","\n","            # 훈련 과정을 출력합니다.\n","            print(\"%d [D loss supervised: %.4f, acc.: %.2f%%] [D loss unsupervised: %.4f] [G loss: %f]\"\n","                % (iteration + 1, d_loss_supervised, 100 * accuracy,\n","                   d_loss_unsupervised, g_loss))"],"metadata":{"id":"RsdXVOJ5UA10"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 하이퍼파라미터를 셋팅합니다.\n","iterations = 8000 # 에폭은 시행착오로 결정한다.\n","batch_size = 32\n","sample_interval = 800 # 800번에 한 번씩 기록함\n","\n","# 지정한 반복 횟수 동안 SGAN을 훈련합니다.\n","train(iterations, batch_size, sample_interval)"],"metadata":{"id":"M3w9xmiliL2E"},"execution_count":null,"outputs":[]}]}
